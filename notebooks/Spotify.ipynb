{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate MP3ToVec embedding for 30s samples of Spotify songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import pickle\n",
    "import csv\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tetic\\Anaconda3\\envs\\Deep\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "class logger(CallbackAny2Vec):\n",
    "    None\n",
    "    \n",
    "embedding_model = gensim.models.Word2Vec.load('word2vec.model')\n",
    "embedding = embedding_model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('..\\speccy_model')\n",
    "batch_size = 100\n",
    "sr         = 22050\n",
    "n_fft      = 2048\n",
    "hop_length = 512\n",
    "n_mels     = model.layers[0].input_shape[1]\n",
    "slice_size = model.layers[0].input_shape[2]\n",
    "slice_time = slice_size * hop_length / sr\n",
    "epsilon_distance = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # key will be Spotify id\n",
    "    mp3tovecs = pickle.load(open('../Pickles_Spotify/spotifytovec.p', 'rb'))\n",
    "    tracktovecs = pickle.load(open('../Pickles_Spotify/tracktovec.p', 'rb'))\n",
    "except:\n",
    "    mp3tovecs = {}\n",
    "    tracktovecs = {}\n",
    "tracks = []\n",
    "with open('popular_tracks.csv', \"r\", encoding='utf-8') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=';')\n",
    "    for row in spamreader:\n",
    "        columns = str(row)[2:-2].split(';')\n",
    "        if columns[0] not in mp3tovecs and columns[3] != '' and columns[3][:5] == 'https':\n",
    "            tracks.append((columns[0], columns[1] + ' - ' + columns[2], columns[3]))\n",
    "num_done = len(mp3tovecs)\n",
    "indices = np.random.permutation(len(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1252 out of 3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [01:25<01:22,  1.68s/it]"
     ]
    }
   ],
   "source": [
    "for batch_num in range(len(indices)//batch_size + 1):\n",
    "    clear_output(True)\n",
    "    print(f'Batch {batch_num + 1 + num_done//batch_size} out of {len(indices)//batch_size + 1 + num_done//batch_size}')\n",
    "    batch = [tracks[idx] for idx in indices[batch_num * batch_size: min((batch_num+1) * batch_size, len(indices))]]\n",
    "    mp3s = {}\n",
    "    try:\n",
    "        with tqdm(batch) as t:\n",
    "            for track in t:\n",
    "                r = requests.get(track[2], allow_redirects=True)\n",
    "                open('temp.mp3', 'wb').write(r.content)\n",
    "                try:\n",
    "                    y, sr = librosa.load('temp.mp3', mono=True)\n",
    "                except:\n",
    "                    print(f'Skipping {track[1]}')\n",
    "                    continue\n",
    "                if y.shape[0] < slice_size:\n",
    "                    print(f'Skipping {track[1]}')\n",
    "                    continue\n",
    "                S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels, fmax=sr/2)\n",
    "                x = np.ndarray(shape=(S.shape[1] // slice_size, n_mels, slice_size, 1), dtype=float)\n",
    "                for slice in range(S.shape[1] // slice_size):\n",
    "                    log_S = librosa.power_to_db(S[:, slice * slice_size : (slice+1) * slice_size], ref=np.max)\n",
    "                    if np.max(log_S) - np.min(log_S) != 0:\n",
    "                        log_S = (log_S - np.min(log_S)) / (np.max(log_S) - np.min(log_S))\n",
    "                    x[slice, :, :, 0] = log_S\n",
    "                mp3s[track[0]] = model.predict(x)\n",
    "    except KeyboardInterrupt:\n",
    "        t.close() # stop the progress bar from sprawling all over the place after a keyboard interrupt\n",
    "        raise\n",
    "    t.close()\n",
    "    mp3_vecs = []\n",
    "    mp3_indices = {}\n",
    "    for mp3 in mp3s:\n",
    "        mp3_indices[mp3] = []\n",
    "        for mp3_vec in mp3s[mp3]:\n",
    "            mp3_indices[mp3].append(len(mp3_vecs))\n",
    "            mp3_vecs.append(mp3_vec / np.linalg.norm(mp3_vec)) # normalize\n",
    "    num_mp3_vecs = len(mp3_vecs)\n",
    "    # this takes up a lot of memory\n",
    "    cos_distances = np.ndarray((num_mp3_vecs, num_mp3_vecs), dtype=np.float16)\n",
    "    print(f'Precalculating cosine distances')\n",
    "    # this needs speeding up\n",
    "    try:\n",
    "        with tqdm(mp3_vecs, unit=\"vector\") as t:\n",
    "            for i, mp3_vec_i in enumerate(t):\n",
    "                for j , mp3_vec_j in enumerate(mp3_vecs):\n",
    "                    if i > j:\n",
    "                        cos_distances[i, j] = cos_distances[j, i] # I've been here before\n",
    "                    elif i < j:\n",
    "                        cos_distances[i, j] = 1 - np.dot(mp3_vec_i, mp3_vec_j)\n",
    "                    else:\n",
    "                        cos_distances[i, j] = 0 # i == j\n",
    "    except KeyboardInterrupt:\n",
    "        t.close() # stop the progress bar from sprawling all over the place after a keyboard interrupt\n",
    "        raise\n",
    "    t.close()        \n",
    "    print(f'Calculating IDF weights')\n",
    "    idfs = []\n",
    "    try:\n",
    "        with tqdm(range(num_mp3_vecs), unit=\"vector\") as t:\n",
    "            for i in t:\n",
    "                idf = 0\n",
    "                for mp3 in mp3s:\n",
    "                    for j in mp3_indices[mp3]:\n",
    "                        if cos_distances[i, j] < epsilon_distance:\n",
    "                            idf += 1 \n",
    "                            break\n",
    "                idfs.append(-np.log(idf / len(mp3s)))\n",
    "    except KeyboardInterrupt:\n",
    "        t.close() # stop the progress bar from sprawling all over the place after a keyboard interrupt\n",
    "        raise\n",
    "    t.close()\n",
    "    print(f'Calculating TF weights')\n",
    "    try:\n",
    "        with tqdm(mp3s, unit=\"mp3\") as t:\n",
    "            for mp3 in t:\n",
    "                vec = 0\n",
    "                for i in mp3_indices[mp3]:\n",
    "                    tf = 0\n",
    "                    for j in mp3_indices[mp3]:\n",
    "                        if cos_distances[i, j] < epsilon_distance:\n",
    "                            tf += 1\n",
    "                    vec += mp3_vecs[i] * tf * idfs[i]\n",
    "                    mp3tovecs[mp3] = vec\n",
    "                    tracktovecs[mp3] = embedding[embedding_model.wv.vocab[mp3].index]\n",
    "    except KeyboardInterrupt:\n",
    "        t.close() # stop the progress bar from sprawling all over the place after a keyboard interrupt\n",
    "        raise\n",
    "    t.close()\n",
    "    pickle.dump(mp3tovecs, open('../Pickles_Spotify/spotifytovec.p', 'wb'))\n",
    "    pickle.dump(tracktovecs, open('../Pickles_Spotify/tracktovec.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
